\chapter{Mecánica Hamiltoniana} 
\refstepcounter{section}
\section{Transformada de Legendre} \refstepcounter{subsection}
Si consideramos una función de una variable $y=f(x)$ tal que $f''(x)\neq 0$, entonces a cada punto le corresponde una sola recta tangente asociada, asociada con su pendiente $f'(x)$ y su ordenada en el origen $g(x) = f(x)-x f'(x)$, tal que $y = f'(x)x + g(x)$, a esta familia de rectas definida por el par $(f'(x),g)$ se le llama \textbf{envolvente} y contiene toda la información original de la función.
\begin{marginfigure}[0cm]
	\includegraphics{envelope.png}
	\labfig{margin2}
\end{marginfigure}
Así tenemos dos nuevas coordenadas $[p,g(p)]$, relacionadas con $[x,f(x)]$ mediante
\vspace{-5pt}
\begin{equation} \label{4.1.1}
    \begin{matrix}
        p(x)=f'(x) && \color{blue}g(p)\color{black}=f(x(p))-x(p)\color{blue}p\color{black} &&[x,f(x)] \mapsto [p,g(p)] \\
        x(p)=(f')^{-1}(p) &&  \color{blue}f(x) \color{black}=p(x)\color{blue}x\color{black}+g(p(x))  && [p,g(p)] \mapsto [x,f(x)]\
    \end{matrix}
\end{equation} \refstepcounter{subsection}
Donde la primera expresión es la \textit{Transformada de Legendre}, y será invertible (la segunda expresión) siempre que $f'(x)$ sea invertible (cierto si $f''(x)\neq 0$).
\subsection{Varias variables}
Si ahora tenemos $f(\{x_i,y_i\})$ donde $\{y_i\}$ son las variables sobre las que queremos hacer la transformada, la transformada es entonces
\begin{equation} \label{4.1.2}
    \begin{matrix}
        p_i(\{x_i,y_i\})=\frac{\partial f}{\partial y_i} && g(\{x_i,\color{blue}p_i\color{black}\}) =f(\{x_i,y_i(\{x_i,p_i\})\}) -\sum_j \color{blue}p_j\color{black} y_j(\{x_i,p_i\})  &&[y_i,f] \mapsto [p_i,g] \\
        y_i(\{x_i,p_i\})=\left[\frac{\partial f}{\partial y_i}\right]^{-1} && f(\{x_i,\color{blue}y_i\color{black}\}) =\sum_j \color{blue}y_j\color{black} p_j (\{x_i,y_i\})  +g(\{x_i,p_i(\{x_i,y_i\})\}) &&[p_i,g] \mapsto [y_i,f]\\
    \end{matrix}
\end{equation} \refstepcounter{subsection}
La transformación será inversible si el jacobiano de $y_i \mapsto p_i$ es no nulo.
\subsubsection{Transformada de Legendre del Lagrangiano}
Ahora si tenemos $\pazocal{L}(\{q_j,\dot{q}_j\};t)$, $\{\dot{q}_j\}$ serán nuestras antiguas variables y las nuevas variables serán $\partial_{\dot{q}_j}\pazocal{L}=p_j$, los momentos generalizados o conjugados. Entonces aplicando (4.1.2) llegamos a (3.1.2)
\begin{equation} \label{4.1.3}
        p_i(\{q_i,\dot{q}_i\};t)=\frac{\partial \pazocal{L}}{\partial q_i} \ \ \ \ \ \  g(\{q_i,p_i\};t) =\pazocal{L}(\{q_i,p_i\};t) -\sum_j^s \dot{q}_j (\{q_i,p_i\}) p_j = -\pazocal{H}
\end{equation} \refstepcounter{subsection}
De esta forma, $\pazocal{H}$ es equivalente a la \textit{Transformada de Legendre} de $\pazocal{L}$ con respecto a los $\dot{q}_j$, y esta es inversible, la demostración de que el jacobiano $[\partial_{\dot{q}_j}p_i]$ es no nulo bajo ciertas circumstancias se deja como un ejercicio al lector.

Se observa que la función $\pazocal{H}$, llamada \textit{Hamiltoniano} es funcionalmente igual a la función energía generalizada $H$ definida en el capítulo anterior, pero en función de las nuevas variables $q_j$ y $p_j$.

De esta forma, no hemos perdido ninguna información del sistema al pasar de $\pazocal{L}$ a $\pazocal{H}$, y a continuación reformularemos las ecuaciones del movimiento en función de esta cantidad de una forma equivalente a la fomulación lagrangiana.
\refstepcounter{section}
\section{Ecuaciones de Hamilton} \refstepcounter{subsection}
Si hacemos la diferencial exacta de $\pazocal{H}$ usando la regla de la cadena tenemos
\begin{equation} \label{4.2.1}
    d\pazocal{H} = \sum^s\left(\frac{\partial \pazocal{H}}{\partial q_j}dq_j+\frac{\partial \pazocal{H}}{\partial p_j}dp_j\right)+\frac{\partial \pazocal{H}}{\partial t} dt
\end{equation} \refstepcounter{subsection}
Si por otro lado hacemos el diferencial de $\pazocal{H}$ desde (3.1.2) o (4.1.3)
\begin{equation} \label{4.2.2}
    d\pazocal{H} = \sum^s\left(p_j d\dot{q}_j+\dot{q}_j dp_j\right)-d\pazocal{L}
\end{equation} \refstepcounter{subsection}
si $d\pazocal{L}$ es por regla de la cadena, y usando (2.2.1) y (2.2.2)
\begin{equation} \label{4.2.3}
    d\pazocal{L}= \sum^s\left(\frac{\partial \pazocal{L}}{\partial q_j}dq_j+\frac{\partial \pazocal{L}}{\partial \dot{q}_j}d\dot{q}_j\right) + \frac{\partial \pazocal{L}}{\partial t}dt = \sum^s\left(\dot{p}_j dq_j+p_j d\dot{q}_j\right) + \frac{\partial \pazocal{L}}{\partial t}dt
\end{equation} \refstepcounter{subsection}
Sustituyendo (4.2.3) en (4.2.2)
\begin{equation} \label{4.2.4}
    d\pazocal{H} = \sum^s p_j d\dot{q}_j+\dot{q}_j dp_j-\sum^s \dot{p}_j dq_j+p_j d\dot{q}_j - \frac{\partial \pazocal{L}}{\partial t}dt = \sum^s \dot{q}_j dp_j-\dot{p}_j dq_j - \frac{\partial \pazocal{L}}{\partial t}dt
\end{equation} \refstepcounter{subsection}
Como $dq_j$, $dp_j$ y $dt$ son funciones independientes y arbitrarias, podemos igualar término a término (4.2.4) y (4.2.1), de tal forma que obtenemos tres ecuaciones
\Large \begin{equation} \label{4.2.5}
    \boxed{\dot{q}_j = \frac{\partial \pazocal{H}}{\partial p_j} \ \ \ \ \ \ \dot{p}_j= -\frac{\partial \pazocal{H}}{\partial q_j}}
\end{equation} \refstepcounter{subsection} \normalsize
Estas dos primeras ecuaciones son las \textit{Ecuaciones de Hamilton} del movimiento o \textit{Ecuaciones canónicas}. Por otro lado tenemos la tercera ecuación, que junto a (3.1.2)
\begin{equation} \label{4.2.6}
    \frac{\partial \pazocal{H}}{\partial t} = - \frac{\partial \pazocal{L}}{\partial t} = \frac{d \pazocal{H}}{dt}
\end{equation} \refstepcounter{subsection}
De esta forma, si $\pazocal{H}$ no depende explícitamente del tiempo, este se conserva.

Para aplicar estas ecuaciones en un sistema holonómico tenemos que hayar primero $\pazocal{L}$, tras esto hallar los momentos generalizados y despues invertir la relación, tal que
\begin{equation} \label{4.2.7}
    p_j = \frac{\partial \pazocal{L}}{\partial \dot{q}_j}=p_j(\{q_k,\dot{q}_k\};t) \rightarrow \dot{q}_j = \dot{q}_j(\{q_k,p_k\};t)
\end{equation} \refstepcounter{subsection}
Entonces usamos la ecuación (4.1.3) con mucho cuidado de reemplazar todas las $\dot{q}_j$ por (4.2.7), y ya tendremos $\pazocal{H}$ en una forma que nos permita resolverlo usando (4.2.5).
\subsection{Variando la acción}
Además, usando (4.1.3) podemos escribir $\pazocal{L}$ como
\begin{equation} \label{4.2.7}
    \pazocal{L}(\{q_i,p_i\};t) = \sum_j^s p_j \dot{q}_j (\{q_i,p_i\};t) -\pazocal{H}(\{q_i,p_i\};t)
\end{equation} \refstepcounter{subsection}
Si hacemos la acción de ese lagrangiano tendremos, y al extremizarla se puede comprobar que se obtienen (4.2.5)
\begin{equation} \label{4.2.7}
    S = \int_{t_A}^{t_B} \left(\sum_j^s p_j \dot{q}_j -\pazocal{H}\right) dt
\end{equation} \refstepcounter{subsection}
Para ello, aplicamos los metodos explicados en el Capítulo 1, teniendo en cuenta que $\pazocal{L}$ no depende de $\dot{p}_i$ 
\[
    \delta S = 0 = \int_{t_A}^{t_B} \delta \pazocal{L} dt = \int_{t_A}^{t_B} \sum_i\left(\frac{\partial \pazocal{L}}{\partial q_i} \delta q_i + \frac{\partial \pazocal{L}}{\partial \dot{q}_i} \delta \dot{q}_i + \frac{\partial \pazocal{L}}{\partial p_i} \delta p_i\right) dt
\]
Integrando el segundo término por partes como en (1.2.1), usando que $\delta \dot{q}_i =  \dot{(\delta q_i)}$
\[
    \delta S = 0 = \int_{t_A}^{t_B} \sum_{i}\left[\left(\frac{\partial \pazocal{L}}{\partial q_i} - \frac{d}{dt}\left(\frac{\partial \pazocal{L}}{\partial \dot{q}_i}\right)\right) \delta q_i + \frac{\partial \pazocal{L}}{\partial p_i}\delta p_i\right] dt
\]
Haciendo las derivadas de $\pazocal{L}$ obtenemos
\begin{equation} \label{4.2.7}
    \delta S = 0 = \int_{t_A}^{t_B} \sum_{i}\left[\left(-\frac{\partial \pazocal{H}}{\partial q_i} - \dot{p}_i\right) \delta q_i + \left(\dot{q}_i-\frac{\partial \pazocal{H}}{\partial p_i}\right)\delta p_i\right] dt
\end{equation} \refstepcounter{subsection}
Y ahora, establecemos que los términos entre paréntesis deben ser 0, puesto que las variaciones son arbitrarias e independientes, obteniendo (4.2.5).
\vspace{-20pt}
\subsubsection{Comparación Ecs. Lagrange-Hamilton}
La formulación Lagrangiana es mejor para tratar con ligaduras, pero la hamiltoniana nos permite reducir el orden de la ecuación diferencial resultante cuando no hay dependencia explícita en una o varias de las $q_j$, puesto que en (3.1.5) $  \pazocal{L}$ sigue dependiendo de $\dot{q}_j$, solo conseguimos reducir en 1 el orden de un ecuación de E-L, mientras que en la formulación hamiltoniana, si una variable es cíclica, es decir $\partial_{q_j}\pazocal{H}=0$, entonces ya hemos resuelto $p_j=\alpha$ por (4.2.5.B) y también por definición $\pazocal{H}$ no depende de $q_j$, de esta forma nos hemos eliminado dos dependencias y reducir el orden en 2 unidades, podemos integrar $q_j$ usando (4.2.5.A) que como no depende de $q_j$ es una EDO separable que podremos resolver integrando al final una vez tengamos el resto de variables resueltas. 
\subsubsection{Ejemplo}
Un ejemplo sencillo es el péndulo simple donde 
\[\pazocal{L}=\frac{1}{2}ml^2\dot{\theta}^2+mgl\cos{\theta} \ \ \ \ \ \ p_\theta = \frac{\partial \pazocal{L}}{\partial \dot{\theta}}=ml^2\dot{\theta} \ \ \ \ \ \ \dot{\theta}=\frac{p_\theta}{ml^2}=\dot{\theta}(p_\theta)\]
Sustituyendo tenemos 
\[\pazocal{H}=p_\theta \dot{\theta} -\pazocal{L}=\frac{p_\theta^2}{ml^2} - \frac{p_\theta^2}{2ml^2}-mgl\cos\theta = \frac{p_\theta^2}{2ml^2}-mgl\cos\theta = T+U\]

Ahora aplicamos (4.2.5.A), tal que $\dot{\theta} = p_\theta/ml^2$, de donde sacamos que $\dot{p}_\theta=ml^2 \ddot{\theta}$ y de (4.2.5.B) sacamos $\dot{p}_\theta=-mgl\sin\theta$, igualando y depejando tenemos $\ddot{\theta} + g/l \sin\theta = 0$, la ecuación del movimiento.
\refstepcounter{section}
\section{Transformaciones canónicas} \refstepcounter{subsection}
Nos va a interesar encontrar un cambio de variables llamado transformaciones canónicas (restringidas, porque no dependen de $t$) de la forma $Q_i=Q_i(\{q_i,p_i\})$ y $P_i=P_i(\{q_i,p_i\})$ invertible que preserve (4.2.5) (Ecs. H.), es decir, que
\begin{equation} \label{4.2.7}
    \pazocal{K} (\{Q_i,P_i\};t) = \pazocal{H} (\{q_j(\{Q_i,P_i\}),p_j(\{Q_i,P_i\})\};t) \implies \dot{Q}_j = \frac{\partial \pazocal{K}}{\partial P_j} \ \ \ \ \ \ \dot{P}_j= -\frac{\partial \pazocal{K}}{\partial Q_j}
\end{equation} \refstepcounter{subsection}
Puesto que si conseguimos encontrar una transformación de este tipo en el que todas las coordenadas sean cíclicas, la resolución de las ecuaciones del movimiento será trivial.
\subsection{Matrices simplécticas (I)}
Vamos a usar la siguente notación para ver que tipos de transformaciones son canónicas, donde los corchetes indican que se recorren todos los índices, es decir que son vectores de $2s$ componentes
\begin{equation} \label{4.2.7}
    \mathbf{z}(\mathbf{Z})=\left[\begin{matrix} \{q_i\}\\ \{p_i\}\end{matrix}\right] \ \ \ \ \ \ \mathbf{Z}(\mathbf{z})=\left[\begin{matrix} \{Q_i\}\\ \{P_i\}\end{matrix}\right]
\end{equation} \refstepcounter{subsection}
\begin{equation} \label{4.2.7}
    \frac{\partial \pazocal{H}}{\partial \mathbf{z}}=\left[\begin{matrix} \left\{\frac{\partial \pazocal{H}}{\partial q_i}\right\} \\ \left\{\frac{\partial \pazocal{H}}{\partial p_i}\right\}\end{matrix}\right] \ \ \ \ \ \ \frac{\partial \pazocal{K}}{\partial \mathbf{Z}}=\left[\begin{matrix} \left\{\frac{\partial \pazocal{K}}{\partial Q_i}\right\} \\ \left\{\frac{\partial \pazocal{K}}{\partial P_i}\right\}\end{matrix}\right]
\end{equation} \refstepcounter{subsection}
\begin{equation} \label{4.2.7}
    \mathbb{J} = \left[\begin{array}{c|c} \mathbb{0}_s & \mathbb{I}_s \\ \hline -\mathbb{I}_s & \mathbb{0}_s \end{array}\right]
\end{equation} \refstepcounter{subsection}
Puede comprobarse entonces que podemos escribir (4.2.5) y (4.3.1) (Ecs. H.) como
\begin{equation} \label{4.2.7}
    \dot{\mathbf{z}} = \mathbb{J} \frac{\partial \pazocal{H}}{\partial \mathbf{z}} \ \ \ \ \ \ \ \dot{\mathbf{Z}} = \mathbb{J} \frac{\partial \pazocal{K}}{\partial \mathbf{Z}}
\end{equation} \refstepcounter{subsection}
Usando la regla de la cadena encontramos la siguiente expresión, donde $\mathbb{M}$ es la jacobiana de la transformación
\begin{equation} \label{4.2.7}
    \dot{\mathbf{Z}} = \mathbb{M}\dot{\mathbf{z}}  \ \ \ \ \ \ \ M_{ij} = \frac{\partial Z_i}{\partial z_j} \ \ \ \ \ \mathbb{M} = \left[\begin{array}{cc} \left\{\frac{\partial Q_i}{\partial q_j}\right\} & \left\{\frac{\partial Q_i}{\partial p_j}\right\} \\  \left\{\frac{\partial P_i}{\partial q_j}\right\} & \left\{\frac{\partial P_i}{\partial p_j}\right\} \end{array}\right]
\end{equation} \refstepcounter{subsection}
Ahora usando la regla de la cadena con (4.3.1) y aplicando el Teorema de la función inversa obtenemos la siguiente relación 
\begin{equation} \label{4.2.7}
    \frac{\partial \pazocal{K}}{\partial Z_j} = \sum_i^{2s} \frac{\partial \pazocal{H}}{\partial z_i} \frac{\partial z_i}{\partial Z_j} = \sum_i^{2s} ({M^{-1}})_{ij} \frac{\partial \pazocal{H}}{\partial z_i} \implies \frac{\partial \pazocal{K}}{\partial \mathbf{Z}} = (\mathbb{M}^{-1})^T \frac{\partial \pazocal{H}}{\partial \mathbf{z}} \rightarrow  \frac{\partial \pazocal{H}}{\partial \mathbf{z}}  = \mathbb{M}^T \frac{\partial \pazocal{K}}{\partial \mathbf{Z}}
\end{equation} \refstepcounter{subsection}
Ahora introducimos (4.3.5) en (4.3.6) y después introducimos (4.3.7)
\begin{equation} \label{4.2.7}
    \mathbb{J} \frac{\partial \pazocal{K}}{\partial \mathbf{Z}} = \mathbb{M}\mathbb{J} \frac{\partial \pazocal{H}}{\partial \mathbf{z}} \rightarrow \mathbb{J} \frac{\partial \pazocal{K}}{\partial \mathbf{Z}} = \mathbb{M}\mathbb{J} \mathbb{M}^T \frac{\partial \pazocal{K}}{\partial \mathbf{Z}} \implies \mathbb{M}\mathbb{J} \mathbb{M}^T = \mathbb{J} 
\end{equation} \refstepcounter{subsection}
Si la jacobiana $\mathbb{M}$ es una matriz simpléctica, es decir, cumple (4.3.8), entonces la transformación es canónica (para cualquier problema, no depende del \textit{Hamiltoniano}).
\newpage
Si se hace el producto matricial de $\mathbb{J} \mathbb{M}^T = \mathbb{M}^{-1}\mathbb{J}$ equivalente a (4.3.8) se pueden obtener unas condiciones más explícitas para concluir si una trasformación es canónica
\begin{equation} \label{4.2.7}
    \begin{split}
        \frac{\partial Q_i(\{q_k,p_k\})}{\partial q_j} = \frac{\partial p_j(\{Q_k,P_k\})}{\partial P_i} \ \ \ \ \ \ \ \ \frac{\partial Q_i(\{q_k,p_k\})}{\partial p_j} = -\frac{\partial q_j(\{Q_k,P_k\})}{\partial P_i} \\ 
        \frac{\partial P_i(\{q_k,p_k\})}{\partial q_j} = -\frac{\partial p_j(\{Q_k,P_k\})}{\partial Q_i} \ \ \ \ \ \ \ \ \frac{\partial P_i(\{q_k,p_k\})}{\partial p_j} = \frac{\partial q_j(\{Q_k,P_k\})}{\partial Q_i}
    \end{split}
\end{equation} \refstepcounter{subsection}
Existe un teorema\sidenote{Sothanaphan, Nat. "Determinants of block matrices with noncommuting blocks" \hspace{1pt}\href{https://arxiv.org/abs/1805.06027}{arXiv:1805.06027l}} que dice que si las matrices $\mathbb{C}$ y $\mathbb{D}$ de una matriz de bloques del mismo tamaño ($\mathbb{A}$, $\mathbb{B}$, $\mathbb{C}$ y $\mathbb{D}$) conmutan, entonces $\det{(\mathbb{J})} = \det{(\mathbb{A}\mathbb{D}-\mathbb{B}\mathbb{C})}$. En el caso de $\mathbb{J}$, $\mathbb{D}= \mathbb{0}$, por lo tanto conmuta con cualquier matriz y el determinante es $\det{(\mathbb{J})} = \det{(\mathbb{0}\mathbb{0}-\mathbb{I}(-\mathbb{I}))} = 1$. Otras propiedades de $\mathbb{J}$ son que $\mathbb{J}^2 = -\mathbb{I}_{2s}$ o que $\mathbb{J}^{-1} = \mathbb{J}^T = -\mathbb{J}$.

Gracias a esto sabemos que $\det{(\mathbb{M}\mathbb{J} \mathbb{M}^T)} = \det{\mathbb{M}} \det{\mathbb{J}} \det{\mathbb{M}^T}=\det{\mathbb{M}}^2 = 1$
\subsection{Funciones generadoras}
El caso anterior es un caso particular para transformaciones canónicas restringidas, ahora vamos a estudiar un caso más general, en el que dependen del tiempo. Como se demostró antes, si tenemos la acción (4.2.9), entonces si su variación es $0$ se verifican las ecuaciones de hamilton, entonces podemos escribir lo siguiente
\begin{equation} \label{4.2.7}
    \delta S = \delta\int_{t_A}^{t_B} \left(\sum_j^s p_j \dot{q}_j -\pazocal{H}(\{q_i,p_i\};t)\right) dt = 0 = \delta\int_{t_A}^{t_B} \left(\sum_j^s P_j \dot{Q}_j -\pazocal{K}(\{Q_i,P_i\};t)\right) dt = \delta \tilde{S}
\end{equation} \refstepcounter{subsection}
Puesto que queremos que las nuevas coordenadas $Q_i=Q_i(\{q_i,p_i\};t)$ y $P_i=P_i(\{q_i,p_i\};t)$ verifiquen (4.2.5) (Ecs. H.) para una cierta función $\pazocal{K}$ que en este caso no necesariamente verifica (4.3.1). (4.3.10) es equivalente a la siguiente expresión, usando lo demostrado en (1.2.5) y que la constante conmuta con la variación
\begin{equation} \label{4.2.7}
    \lambda\left(\sum_j^s p_j \dot{q}_j -\pazocal{H}\right) = \sum_j^s P_j \dot{Q}_j -\pazocal{K} +  \frac{dF(\{q_i,p_i\},\{Q_i,P_i\};t)}{dt}
\end{equation} \refstepcounter{subsection}
La constante $\lambda$ es un factor de escala, si por ejemplo $Q_j = \mu q_j$, $P_j = \nu p_j$ y $\pazocal{K} = \mu \nu \pazocal{H}$, entonces tenemos que la ecuación de arriba nos queda $\mu\nu\left(p_j \dot{q}_j -\pazocal{H}\right) = P_j \dot{Q}_j -\pazocal{K}$ (usando el criterio de suma de indices de Einstein), por lo tanto $\lambda$ no es nada mas que el producto de dos constantes de escala, y a partir de una transformación canónica, siempre podemos encontrar otra simplemente reescalando tal que $\lambda = 1$, así, para simplificar, nos centraremos en la siguiente expresión 
\begin{equation} \label{4.2.7}
    \sum_j^s p_j \dot{q}_j -\pazocal{H} = \sum_j^s P_j \dot{Q}_j -\pazocal{K} + \frac{dF(\{q_i,p_i\},\{Q_i,P_i\};t)}{dt}
\end{equation} \refstepcounter{subsection}
La función $F$, cuya variación de su acción se anula porque las variaciones de todas las coordenadas se anulan en los extremos, se denomina \textit{Función generadora}. Se llama así porque nos va a permitir generar transformaciones canónicas a partir de transformaciones canónicas parciales.
\newpage
Ahora, la dependencia de esa función es redundante, puesto que tenemos dos relaciones $Q_i=Q_i(\{q_i,p_i\};t)$ y $P_i=P_i(\{q_i,p_i\};t)$, o equivalentes obtenidas despejando esas, entonces podemos estudiar casos concretos de dependencias de $F$ en función de qué relaciones tengamos.

Vamos a suponer primero que $F$ tiene la dependencia $F = F_1(\{q_i,Q_i\};t)$, entonces haciendo la regla de la cadena en (4.3.12) tenemos
\begin{equation} \label{4.2.7}
    \sum_j^s p_j \dot{q}_j -\pazocal{H} = \sum_j^s P_j \dot{Q}_j -\pazocal{K} + \frac{\partial F_1}{\partial t} + \sum_j^s \left(\frac{\partial F_1}{\partial q_j}\dot{q}_j + \frac{\partial F_1}{\partial Q_j}\dot{Q}_j\right)
\end{equation} \refstepcounter{subsection}
Para que se cumpla esta ecuación idénticamente deben cumplirse las siguientes relaciones 
\begin{equation} \label{4.2.7}
    \frac{\partial F_1}{\partial q_i} = p_i \ \ \ \ \ \ \ \ \frac{\partial F_1}{\partial Q_i} = -P_i \ \ \ \ \ \ \ \ \frac{\partial F_1}{\partial t} = \pazocal{K}-\pazocal{H}
\end{equation} \refstepcounter{subsection}
Entonces si por ejemplo conocemos $P_i=P_i(\{q_j,Q_j\};t)$ pero no $Q_i$, podemos integrar primero la segunda expresión de (4.3.14), teniendo $F_1 = -\sum_j \int P_j dQ_j + h(\{q_j\};t)$, con h arbitraria, entonces introducimos en la primera expresión y tendremos $p_i \{q_j,Q_j\}= -\sum_j\int \partial_{q_i} P_j dQ_j + \partial_{q_i} h(\{q_j\};t)$, y entonces ahora podemos invertir la relación para tener $Q_i=Q_i(\{q_j,p_j\};t)$, ahora volvemos a sustituir esta última expresión en $P_i$, así, obtenemos una familia de transformaciones canónicas, y también obtenemos la familia $\pazocal{K} = \pazocal{H}-\sum_j\int \partial_t P_j dQ_j + \partial_t h(\{q_j\};t)$ con respecto a las cuales se verifican las ecuaciones canónicas. También podríamos haber partido de de $p_i=p_i(\{q_j,Q_j\};t)$ para obtener otra familia de transfomaciones canónicas.

Si tenemos otras relaciones, como por ejemplo $Q_i=Q_i(\{q_j,P_j\};t)$, podemos definir otra función $F = F_2(\{q_j,P_j\};t) - \sum_j Q_j P_j$, siendo $F_2$ equivalente a una Transformada de Legendre de $F_1$ en su segundo conjunto de variables, pero $F \neq F_1(\{q_i,Q_i(\{q_j,P_j\})\};t)$, sino que en general es una función de todas variables como se indicó en (4.3.12). Si sustituimos esta nueva dependencia y aplicamos la regla de la cadena teniendo en cuenta esta dependencia obtenemos una ecuación similar a (4.3.13) en la que se cancelan algunos términos y obtenemos las siguientes relaciones que se deben cumplir para que esta sea cierta
\begin{equation} \label{4.2.7}
    \frac{\partial F_2}{\partial q_i} = p_i \ \ \ \ \ \ \ \ \frac{\partial F_2}{\partial P_i} = Q_i \ \ \ \ \ \ \ \ \frac{\partial F_2}{\partial t} = \pazocal{K}-\pazocal{H}
\end{equation} \refstepcounter{subsection}
Podemos aplicar este procedimiento de hacer 'como' una Transformada de Legendre dos veces con las dos expresiones anteriores para obtener otras dos funciones distintas con sus relaciones correspondientes. Estas 4 funciones generadoras se resumen en la siguiente tabla
\begin{equation} \label{4.2.7}
        \arraycolsep=3pt\def\arraystretch{1.5}
        \begin{array}{|c|ccc|} \hline \mbox{Función generadora} & & \mbox{Derivadas} & \\ \hline 
            F = F_1(\{q_i,Q_i\};t) & \frac{\partial F_1}{\partial q_i} = p_i &  \frac{\partial F_1}{\partial Q_i} = -P_i & \frac{\partial F_1}{\partial t} = \pazocal{K}-\pazocal{H} \\ \hline 
            F = F_2(\{q_i,P_i\};t) -\sum_j Q_j P_j& \frac{\partial F_2}{\partial q_i} = p_i &  \frac{\partial F_2}{\partial P_i} = Q_i  & \frac{\partial F_2}{\partial t} = \pazocal{K}-\pazocal{H} \\ \hline 
            F = F_3(\{p_i,Q_i\};t) +\sum_j q_j p_j& \frac{\partial F_3}{\partial p_i} = -q_i &  \frac{\partial F_3}{\partial Q_i} = -P_i  & \frac{\partial F_3}{\partial t} = \pazocal{K}-\pazocal{H}\\ \hline 
            F = F_4(\{p_i,P_i\};t) +\sum_j (q_j p_j - Q_j P_j)& \frac{\partial F_4}{\partial p_i} = -q_i & \frac{\partial F_4}{\partial P_i} = Q_i  & \frac{\partial F_4}{\partial t} = \pazocal{K}-\pazocal{H}\\ \hline 
        \end{array}
\end{equation} \refstepcounter{subsection}
Entonces podremos aplicar el procedimiento que he explicado antes de forma análoga para $F_i$ cuando tengamos una relación de dependencias de variables $A_i=A_i(\{b_j,C_j\};t)$ (también es posible que solo dependa de unas de ellas, por lo general las primeras) igual a la de $F_i$ especificada en (4.3.16)

Es posible (incluso necesario en algunos casos) mezclar funciones generadoras cuando tengamos varios grados de libertad, es decir, usar distintas funciones generadoras para distintas variables.
\subsection{Matrices simplécticas (II)}
Como se observa en (4.3.15), si la función generadora no depende explícitamente del tiempo, entonces $\pazocal{H} = \pazocal{K}$ y se recupera la condición (4.3.1) usada para demostrar (4.3.8) cuando la transformación canónica no dependía explítamente del tiempo, por lo tanto ambos acercamientos son equivalentes.

Ahora, queremos saber que ocurre con la condición (4.3.8) cuando la transformación depende explícitamente del tiempo, para ello vamos a desarrollar en pequeñas variaciones mezclando ambos acercamientos.

Primero, escribimos una transformación infinitesimal de la siguiente forma forma, 
\begin{equation} \label{4.2.7}
    \mathbf{Z} = \mathbf{Z}(\mathbf{z},t) = \vec{\zeta}(\mathbf{Z}(\mathbf{z},t_0),t) \rightarrow \vec{\zeta}(\vec{\mu},\epsilon) = \vec{\mu} + \epsilon \vec{\eta}(\vec{\mu}) +O(\epsilon^2) \ \ \ \ \ \ \epsilon = t-t_0 \ \ \ \ \ \ \vec{\mu} = \mathbf{Z}(\mathbf{z},t_0) \ \ \ \ \ \  \vec{\eta}(\mathbf{z}(\vec{\mu})) = \left.\frac{\partial \mathbf{Z}}{\partial t}\right|_{t=t_0}
\end{equation} \refstepcounter{subsection}
Ahora podemos escribir la siguiente función generadora, dónde $\tilde{q}_i$ y $\tilde{p}_i$ son las componentes de $\vec{\mu}$, el primer sumatorio es la función generadora de la identidad

\vspace{-15pt}
\begin{equation} \label{4.2.7}
    F_2(\{\tilde{q}_i,P_i\};t) = \sum_j^s \tilde{q}_j P_j + \epsilon G(\{\tilde{q}_i,P_i\}) + O(\epsilon^2)
\end{equation} \refstepcounter{subsection}

\vspace{-20pt}
Usando (4.3.16) nos da la relación con la transformación anterior

\vspace{-18pt}
\begin{equation} \label{4.2.7}
    \begin{split}
        \tilde{p}_i = P_i + \epsilon \frac{\partial G}{\partial \tilde{q}_i} + O(\epsilon^2) \ \ \ \ \ P_i-\tilde{p}_i &= \epsilon \frac{\partial G}{\partial \tilde{q}_i} + O(\epsilon^2)= \epsilon \eta_i +O(\epsilon^2)\ \ \ i = 1,\dots,s\\ 
        Q_i = \tilde{q}_i + \epsilon \frac{\partial G}{\partial P_i} + O(\epsilon^2)\ \ \ \ \ Q_i-\tilde{q}_i &= -\epsilon \frac{\partial G}{\partial P_i} + O(\epsilon^2)= \epsilon \eta_i +O(\epsilon^2)\ \ \ i = s+1,\dots,2s \\
        \pazocal{K} &= \pazocal{H} + G
    \end{split}
\end{equation} \refstepcounter{subsection}

\vspace{-30pt}
Ahora en la siguiente expresión podemos sustituir $P_i$ y expandir

\vspace{-15pt}
\begin{equation} \label{4.2.7}
        \epsilon \frac{\partial G}{\partial P_i} = \epsilon \frac{\partial G (\{\tilde{q}_i,\tilde{p}_i + \epsilon \partial{\tilde{q}_i} G\})}{\partial (\tilde{p}_i + \epsilon \partial{\tilde{q}_i} G)} = \epsilon \frac{\partial G (\{\tilde{q}_i,\tilde{p}_i + 0 \cdot  \partial_{\tilde{q}_i} G\})}{\partial (\tilde{p}_i + 0 \cdot \partial_{\tilde{q}_i} G)} +\epsilon^2 \left.\frac{\partial^2 G (\{\tilde{q}_i,P_i\})}{\partial^2 P_i }\right|_{\epsilon=0} \hspace{-10pt}= \epsilon \frac{\partial G}{\partial \tilde{p}_i} + O(\epsilon^2)
\end{equation} \refstepcounter{subsection}
Entonces ahora podemos escribir sustituyendo en (4.3.19), considerando $G = G(\{\tilde{q}_i,\tilde{p}_i\})$
\begin{equation} \label{4.2.7}
    \begin{split}
        \eta_i &= \ \ \ \frac{\partial G}{\partial \tilde{q}_i} +O(\epsilon) \ \ \ \ i = 1,\dots,s\\ 
        \eta_i &= -\frac{\partial G}{\partial \tilde{p}_i} +O(\epsilon) \ \ \ \ i = s+1,\dots,2s
    \end{split} \implies \vec{\eta} = \mathbb{J} \frac{\partial G}{\partial \vec{\mu}} +O(\epsilon)
\end{equation} \refstepcounter{subsection}
Si ahora calculamos el jacobiano ($\mathbb{M}$) de $\vec{\zeta}$ (4.3.17) usando (4.3.21), llegamos a la siguiente expresión, donde $\mathbb{H}$ es la Hessiana de $G$
\begin{equation} \label{4.2.7}
    \mathbb{M} = \frac{\partial \vec{\zeta}}{\partial \vec{\mu}} = \mathbb{I} + \epsilon \mathbb{J} \mathbb{H} + O(\epsilon^2) \ \ \ \ \ \ \mathbb{H}_{ij} = \frac{\partial^2 G}{\partial \mu_i \partial \mu_j}
\end{equation} \refstepcounter{subsection}
Ahora podemos que verifica la condición (4.3.8) a primer orden, aplicando el Teorema de Schwarz ($\mathbb{H}^T = \mathbb{H}$) y que $\mathbb{J}^T = -\mathbb{J}$
\begin{equation} \label{4.2.7}
    \begin{split}
        \mathbb{M}^T = \mathbb{I} + \epsilon \mathbb{H}^T \mathbb{J}^T  + O(\epsilon^2) &= \mathbb{I} - \epsilon \mathbb{H} \mathbb{J}  + O(\epsilon^2)\\ 
        \mathbb{J} = \left(\mathbb{I} + \epsilon  \mathbb{J}\mathbb{H} + O(\epsilon^2)\right) \mathbb{J} \left(\mathbb{I} - \epsilon \mathbb{H} \mathbb{J}  + O(\epsilon^2)\right) &= \mathbb{J} + \epsilon  \mathbb{J}\mathbb{H}\mathbb{J} -  \epsilon  \mathbb{J}\mathbb{H}\mathbb{J} + O(\epsilon^2) = \mathbb{J} + O(\epsilon^2)
    \end{split}
\end{equation} \refstepcounter{subsection}
Por lo tanto podemos concluir que la transformación $\mathbf{Z}(\mathbf{z};t_0) \rightarrow \mathbf{Z}(\mathbf{z};t_0 + \epsilon)$ es canónica ($\mathbf{z} \rightarrow \mathbf{Z}(\mathbf{z};t_0)$ tiene que ser canónica en primer lugar) y que verifica (4.3.8) a primer orden.

De esta forma podemos escribir la transformación original como 
\begin{equation} \label{4.2.7}
    \mathbf{Z}(\mathbf{z},t) = \lim_{\epsilon \rightarrow 0 \ \ n \rightarrow \infty} \vec{\zeta}_n(\vec{\zeta}_{n-1}(\dots(\vec{\zeta}_0))) \ \ \ \ \ \vec{\zeta}_0 = \mathbf{Z}(\mathbf{z},t_0) \ \ \ \  n = \frac{t_n-t_0}{t_1-t_0} = \frac{t-t_0}{\epsilon} \ \ \ \ \ \ \mathbb{J} = \mathbb{M}_\mathbf{z}\mathbb{J}\mathbb{M}_\mathbf{z}^T
\end{equation} \refstepcounter{subsection}
Esta expresión es equivalente a aplicar el método de Euler para integrar una EDO de aplicando la ecuación $\vec{\zeta}$ de forma iterativa, además, es sencillo demostrar que la jacobiana de la composición es el producto de las jacobianas, pudiendo sustuir en (4.3.24) y usando (4.3.23) iterativamente comprobar que la expresión es cierta. Así, hemos demostrado que cualquier transformación, incluso si depende del tiempo, es canónica si y sólo si su jacobiano $\mathbb{M}$ verifica (4.3.8) ($\mathbb{J} = \mathbb{M}_\mathbf{z}\mathbb{J}\mathbb{M}_\mathbf{z}^T$) (aunque si depende del tiempo no necesariamente $\pazocal{H}=\pazocal{K}$).
Se puede demostrar además que las transfomaciones canónicas, y concreto las matrices $\mathbb{M}$ que verifican (4.3.8) ($\mathbb{J} = \mathbb{M}_\mathbf{z}\mathbb{J}\mathbb{M}_\mathbf{z}^T$) forman un grupo bajo la operación composición.


\refstepcounter{section}
\section{Paréntesis de Poisson (I)} \refstepcounter{subsection}
Sea $f=f(\{q_j,p_j\};t)$ una función de las coordenadas canónicas, podemos hacer su derivada total con respecto al tiempo, tal que
\begin{equation} \label{4.4.1}
    \frac{d f}{dt} = \sum^s \left(\frac{\partial f}{\partial q_j}\dot{q}_j+\frac{\partial f}{\partial p_j}\dot{p}_j\right) + \frac{\partial f}{\partial t}
\end{equation} \refstepcounter{subsection}
Usando (3.2.5) (Ecs. H.) llegamos a 
\begin{equation} \label{4.4.2}
\frac{d f}{dt} = \sum^s \left(\frac{\partial f}{\partial q_j}\frac{\partial \pazocal{H}}{\partial p_j}-\frac{\partial f}{\partial p_j}\frac{\partial \pazocal{H}}{\partial q_j}\right) + \frac{\partial f}{\partial t} = [f,\pazocal{H}]_\mathbf{z} + \frac{\partial f}{\partial t}
\end{equation} \refstepcounter{subsection}
Dónde $[f,\pazocal{H}]$ es el \textit{paréntesis de Poisson} de $f$ y $\pazocal{H}$, en general lo definimos para dos funciones y unas ciertas variables canónicas $\mathbf{z}$ como
\begin{equation} \label{4.4.3}
    [f,g]_\mathbf{z}=  \sum^s \left(\frac{\partial f}{\partial q_j}\frac{\partial g}{\partial p_j}-\frac{\partial f}{\partial p_j}\frac{\partial g}{\partial q_j}\right) = \left[\frac{\partial f}{\partial \mathbf{z}}\right]^T \hspace{-7pt} \mathbb{J} \left[\frac{\partial g}{\partial \mathbf{z}}\right]
\end{equation} \refstepcounter{subsection}
Sus propiedades algebraicas son muy similares a aquellas del producto vectorial puesto que su expresión es muy similar, puesto que ambos son ejemplos de álgebras de Lie, sus propiedades son y se pueden verificar reemplazando en (4.4.3).
\begin{itemize}
    \item Es alternada $[f,g]=-[g,f]$ y $[f,f]=0$.
    \item Si $[f,g]=0 \iff [f,g]=[g,f]=0$ las funciones conmutan.
    \item Es bilineal, $[f,\alpha g + \beta h] = \alpha [f,g] + \beta [f,h]$ en ambas entradas.
    \item Existe una regla del producto $[f,gh]=g[f,h]+[f,g]h$.
    \item Se verifica la \textit{Identidad de Jacobi}, $\left[f,[g,h]\right]+\left[h,[f,g]\right]+\left[g,[h,f]\right]=0$.
\end{itemize}
%Otra regla del producto que se verifica, usando la conmutividad de las derivadas parciales, es $\frac{\partial}{\partial t}[f,g]=[\frac{\partial f}{\partial t},g]+[f,\frac{\partial g}{\partial t}]$.

Si la función $f$ no depende explícitamente del tiempo, entonces si $f$ conmuta con $\pazocal{H}$, eso implica por (4.4.2) y las propiedades anteriores, que $f$ se conserva.

Además, si tenemos dos cantidades conservadas $f$ y $g$, entonces tenemos que, usando la \textit{Identidad de Jacobi}, se conserva su paréntesis
\begin{equation} \label{4.4.5}
    \frac{d}{dt}[f,g]_\mathbf{z}=0
\end{equation} \refstepcounter{subsection}
Si hacemos $[q_k,\pazocal{H}]$ y $[p_k,\pazocal{H}]$ aplicando (4.4.3) y (3.2.5) (Ecs. H.), obtenemos las ecuaciones del movimiento expresadas en términos de \textit{paréntesis de Poisson}.
\begin{equation} \label{4.4.6}
    \boxed{[q_k,\pazocal{H}]_\mathbf{z} = \dot{q}_k \ \ \ \ \ [p_k,\pazocal{H}]_\mathbf{z}=\dot{p}_k} \iff [\mathbf{z},\pazocal{H}]_\mathbf{z} = \dot{\mathbf{z}}
\end{equation} \refstepcounter{subsection}
Tenemos también los paréntesis de \textit{paréntesis de Poisson} fundamentales
\begin{equation} \label{4.4.7}
    [q_k,q_l]_\mathbf{z}=[p_k,p_l]_\mathbf{z}=0 \ \ \ \ \ [q_k,p_l]_\mathbf{z}=\delta_{kl} \iff [\mathbf{z},\mathbf{z}]_\mathbf{z} = \mathbb{J}
\end{equation} \refstepcounter{subsection}

\subsection{Invariancia bajo T. Canónicas}
Como el Corchete de Poisson esta relacionado con las ecuaciones de Hamilton y con la evolución temporal de funciones del sistema, esperamos que este se mantenga invariante bajo una transformación canónica, demostrémoslo.

Vamos a suponer ahora unas transformaciones $\mathbf{Z}=\mathbf{Z}(\mathbf{z};t)$ canónicas, tal que $\mathbb{J} = \mathbb{M}_\mathbf{z}\mathbb{J}\mathbb{M}_\mathbf{z}^T$ para la jacobiana de la transformación $\mathbb{M}$. Usando la expresión (4.3.7) para una función arbitraria y su equivalente en las nuevas coordenadas, en vez tomar especificamente el \textit{Hamiltoniano}, tenemos
\begin{equation} \label{4.4.7}
    [f,g]_\mathbf{z} = \left[\frac{\partial f}{\partial \mathbf{z}}\right]^T \hspace{-7pt} \mathbb{J} \left[\frac{\partial g}{\partial \mathbf{z}}\right] = \left[\mathbb{M}^T\frac{\partial f}{\partial \mathbf{Z}}\right]^T \hspace{-7pt} \mathbb{J} \left[\mathbb{M}^T\frac{\partial g}{\partial \mathbf{Z}}\right] = \left[\frac{\partial f}{\partial \mathbf{Z}}\right]^T \hspace{-7pt}\mathbb{M} \mathbb{J}\mathbb{M}^T \left[\frac{\partial g}{\partial \mathbf{Z}}\right] = \left[\frac{\partial f}{\partial \mathbf{Z}}\right]^T \hspace{-7pt} \mathbb{J} \left[\frac{\partial g}{\partial \mathbf{Z}}\right] = [f,g]_\mathbf{Z}
\end{equation} \refstepcounter{subsection}
De esta forma, el paréntesis queda invariante si y sólo si la transfomación es canónica. De hecho podemos reformular la condición de que una transformación sea canónica a que mantenga el paréntesis invariante, puesto que son equivalentes.

Además, ahora no vamos a especificar las coordenadas con respecto a las cuales hacemos el paréntesis y todas las fórmulas de la sección anterior son válidas para cualquier conjunto de coordendas canónicas.
\subsection{Corchete de Lagrange}
Podemos definir otra operación similar, llamada Corchete de Lagrange, que se puede demostrar de manera muy similar a (4.4.7) que se conserva bajo transformaciones canónicas
\begin{equation} \label{4.4.3}
    \{f,g\}=  \sum^s \left(\frac{\partial q_j}{\partial f}\frac{\partial p_j}{\partial g}-\frac{\partial p_j}{\partial f}\frac{\partial q_j}{\partial g}\right) = \left[\frac{\partial \mathbf{z}}{\partial f}\right]^T \hspace{-7pt} \mathbb{J} \left[\frac{\partial \mathbf{z}}{\partial g}\right]
\end{equation} \refstepcounter{subsection}
A priori, parece como hacer la 'inversa' de los corchetes de Poisson, y en cierto sentido lo es, si $\mathbf{u}$ son $2s$ funciones independientes, puede demostrarse la siguiente expresión
\begin{equation} \label{4.4.3}
    [\mathbf{u},\mathbf{u}]\{\mathbf{u},\mathbf{u}\}=  -1
\end{equation} \refstepcounter{subsection}
\refstepcounter{section}
\section{Espacio de fase} \refstepcounter{subsection}
El hecho de que solo haya una sola solución para las ecuaciones del movimiento, es decir, que solo hay una posible trayectoria dadas unas condiciones dadas, significa que el sistema con el que estamos tratando es \textit{determinista}.

Si es el espacio de configuración es $\{q_j\}$ para un $t$ dado, entonces definimos el \textbf{Espacio de fase} como $\{q_j,p_j\}$, donde $\{p_j\}$ es el espacio de momentos o impulsos.

Este espacio es de dimensión $2s$ y nos da toda la información dinámica del sistema pues nos permite predecir su evolución, puesto que con unas condiciones iniciales de posición y momento (o velocidad) definidas por unas coordendas del espacio de fase, podemos usar (4.2.5) (Ecs. H.) para hallar la evolución del sistema.
\subsection{Diagrama de fases}
Es la trayectoria que sigue un sistema en el espacio de fase, normalmente representada en un conjunto de $s$ planos bidimensionales como una curva en cada uno de ellos, cuyos ejes representan $q_j$ y $p_j$, donde por cada punto en un $t$ dado solo puede pasar una sola trayectoria, de lo contrario el sistema no sería determinista, ya que de unas mismas condiciones iniciales podría evolucionar de varias formas.

Además si $\pazocal{H}$ se conserva, entonces por cada punto del espacio de fase solo puede pasar una trayectoria independientemente del tiempo.

\subsubsection{Ejemplo}
\begin{marginfigure}[0cm]
	\includegraphics{phase.png}
	\labfig{margin3}
\end{marginfigure}
Como ejemplo vamos a ver un péndulo, tomando las expresiones del ejemplo de (4.2), donde las coordenadas del espacio de fases son $(\theta,p_\theta)$, si $\theta \ll 1$, tenemos $\ddot{\theta}+\frac{g}{l}\theta=0$, cuya solución, donde $\omega^2=g/l$, es
\[
    \begin{split}
        \theta = A \sin{(\omega t + \theta_0)}+ B \cos{(\omega t + \theta_0)} \ \ \ \ \dot{\theta} &= A\omega \cos{(\omega t + \theta_0)}- B \omega \sin{(\omega t + \theta_0)} \ \ \ \ p_\theta = ml^2 \dot{\theta}\\ 
        \theta^2 &+ \frac{p_\theta^2}{\omega^2 m^2l^4}=A^2+B^2 \mbox{ (elipse)}
    \end{split}    
\]

\vspace{-35pt}

\subsection{Teorema de Liouville} \refstepcounter{subsection}
\subsubsection{Volumen en el espacio de fase}
Definimos el volumen en el espacio de fases como
\begin{equation} \label{4.3.1}
    V = \int \dots \int \prod_j^s d q_j d p_j
\end{equation} \refstepcounter{subsection}
Donde $d q_j d p_j$ son elementos de área en uno de los $s$ planos. Es sencillo demostrar que una transformación deja invariante el volumen puesto que al hacer un cambio de variable hay que introducir el valor absoluto del determinante de la jacobiana, que como demostramos, es $1$, por lo tanto $dV$ se conserva y $V$ también.

Si ahora tenemos una serie de condiciones iniciales distribuidas dentro de una región volumétrica del espacio de fases, siendo $\pazocal{N}$ el número de condiciones iniales dentro de $V$, entonces si consideramos como la frontera de $V$ se transforma con el tiempo para dar $V'$, entonces $\pazocal{N}$ se conserva, puesto que para que una trayectoria entre o salga del volumen sería necesario que cortase una trayectoria de la frontera, lo cual no puede ocurrir en un sistema determinista.
\subsubsection{Teorema de Liouville} \refstepcounter{subsection}
El volumen $V(S)$ dentro de una superficie $S(t)$ del espacio de fase se conserva.
\begin{equation} \label{4.3.2}
    \frac{dV}{dt}=0 \implies \frac{d\rho}{dt} = 0 \ \ \ \ \rho = \frac{\pazocal{N}}{V}
\end{equation} \refstepcounter{subsection}

\textbf{Demostración}

Sea $\mathbf{\nabla} = (\mathbf{\nabla}_\textbf{q},\mathbf{\nabla}_\textbf{p})$, entonces la divergencia de $\dot{\mathbf{z}}$, tal que
\begin{equation} \label{4.3.4}
    \mathbf{\nabla} \cdot \dot{\mathbf{z}} = \sum^s \frac{\partial \dot{q}_j}{\partial q_j} + \frac{\partial \dot{p}_j}{\partial p_j}
\end{equation} \refstepcounter{subsection}
entonces por el Teorema de la Divergencia
\begin{equation} \label{4.3.5}
    \int_V{\mathbf{\nabla} \cdot \dot{\mathbf{z}} dV} = \int_S \dot{\mathbf{z}} \cdot d\mathbf{S}
\end{equation} \refstepcounter{subsection}
La variación de $V$ en términos del tiempo es la siguiente, ya que $\dot{\mathbf{z}}dt$ indica como se mueven las partículas de dentro de $V$, y multiplicando por $d\mathbf{S}$ nos indica como varía el volumen infinitesimalmente en un punto de la superficie, integrando en la superficie para ver la variación total de $V$ tenemos
\begin{equation} \label{4.3.6}
    dV=\int_S \dot{\mathbf{z}} \cdot d\mathbf{S} dt \implies \frac{dV}{dt} = \int_S \dot{\mathbf{z}} \cdot d\mathbf{S}
\end{equation} \refstepcounter{subsection}
Combinando (4.4.4), (4.4.5) y sustituyendo (4.4.3) llegamos a 
\begin{equation} \label{4.3.7}
    \frac{dV}{dt} = \int_V{\mathbf{\nabla} \cdot \dot{\mathbf{z}} dV} = \int_V{\left(\sum^s \frac{\partial \dot{q}_j}{\partial q_j} + \frac{\partial \dot{p}_j}{\partial p_j}\right)dV}
\end{equation} \refstepcounter{subsection}
Ahora usando (4.2.5) (Ecs. H.) y que las parciales conmutan.
\begin{equation} \label{4.3.8}
    \frac{dV}{dt} = \int_V{\left(\sum^s \frac{\partial \pazocal{H}}{\partial q_j p_j} - \frac{\partial \pazocal{H}}{\partial p_j q_j}\right)dV} = 0
\end{equation} \refstepcounter{subsection}


\refstepcounter{section}
\section{Paréntesis de Poisson (II)} \refstepcounter{subsection}